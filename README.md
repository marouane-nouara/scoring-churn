# ğŸ¦ Scoring Churn â€” DÃ©tection de dÃ©part clients

> **Licence Professionnelle Data Mining**
> Mise en place d'une solution de dÃ©tection de dÃ©part des clients
>
> ğŸ‘¥ Ã‰quipe : Nicolas Â· Marouane Â· Ilyes Â· Ephraim

---

## ğŸ“Œ Contexte et objectifs

Une banque observe une **hausse des rÃ©siliations** de cartes de crÃ©dit. L'objectif de ce projet est de dÃ©velopper un **modÃ¨le prÃ©dictif probabiliste** capable d'anticiper les clients Ã  risque de churn (attrition) avant qu'ils ne partent.

### Pourquoi ce projet ?
- ğŸ“‰ CoÃ»t d'acquisition d'un nouveau client = 5Ã— le coÃ»t de fidÃ©lisation
- ğŸ¯ Cibler les bonnes actions de rÃ©tention nÃ©cessite d'identifier les clients Ã  risque
- ğŸ“Š Dataset de **+10 000 clients** avec 19 caractÃ©ristiques (Ã¢ge, revenu, comportement transactionnel...)

---

## ğŸ—ï¸ Pipeline ML

```
DonnÃ©es brutes (CSV)
       â”‚
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  1. Chargement      â”‚  loader.py
â”‚     & Renommage     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  2. Nettoyage       â”‚  cleaner.py
â”‚  â€¢ Valeurs manq.    â”‚  â†’ MÃ©diane / Moyenne / Mode
â”‚  â€¢ Outliers IQR     â”‚  â†’ Clipping [Q1âˆ’1.5Ã—IQR, Q3+1.5Ã—IQR]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  3. Feature Eng.    â”‚  engineering.py
â”‚  â€¢ DiscrÃ©tisation   â”‚  â†’ 4 classes par quartile
â”‚  â€¢ Regroupement     â”‚  â†’ ModalitÃ©s rares â†’ "Autre"
â”‚  â€¢ WOE / IV         â”‚  â†’ Pouvoir prÃ©dictif des variables
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  4. Tests stats     â”‚  stats_tests.py
â”‚  â€¢ Mann-Whitney     â”‚  â†’ Variables quantitatives
â”‚  â€¢ ChiÂ² + V Cramer  â”‚  â†’ Variables qualitatives
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  5. ModÃ©lisation (SMOTE + Balanced) â”‚  train.py
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ RÃ©gression     â”‚ â”‚   ForÃªt     â”‚ â”‚
â”‚  â”‚ Logistique     â”‚ â”‚  AlÃ©atoire  â”‚ â”‚
â”‚  â”‚ AUC : 0.94     â”‚ â”‚ AUC : 0.96  â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  6. Outputs         â”‚
â”‚  â€¢ Courbes ROC      â”‚
â”‚  â€¢ Matrices confus. â”‚
â”‚  â€¢ Import. variablesâ”‚
â”‚  â€¢ ModÃ¨les .pkl     â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ“Š RÃ©sultats des modÃ¨les

| MÃ©trique | RÃ©gression Logistique | ForÃªt AlÃ©atoire |
|----------|----------------------|-----------------|
| **AUC-ROC** | **0.94** | **0.96** âœ… |
| PrÃ©cision (rÃ©siliÃ©s) | 0.60 | 0.86 |
| Rappel (rÃ©siliÃ©s) | 0.87 | 0.70 |
| F1-score (rÃ©siliÃ©s) | 0.71 | 0.77 |
| PrÃ©cision globale | 76% | 93% |

> ğŸ’¡ **Recommandation** : La **ForÃªt AlÃ©atoire** offre de meilleures performances globales (AUC 0.96, prÃ©cision 93%). La RÃ©gression Logistique reste pertinente si l'on veut **maximiser le rappel** (dÃ©tecter un maximum de rÃ©siliÃ©s, quitte Ã  avoir plus de faux positifs).

---

## ğŸ”‘ Variables les plus prÃ©dictives

Les **3 variables clÃ©s** identifiÃ©es par les deux modÃ¨les :

| Rang | Variable | Importance |
|------|----------|------------|
| ğŸ¥‡ | Nombre total de transactions | â˜…â˜…â˜…â˜…â˜… |
| ğŸ¥ˆ | Montant total de transactions | â˜…â˜…â˜…â˜…â˜… |
| ğŸ¥‰ | Variation totale des transactions Q4/Q1 | â˜…â˜…â˜…â˜…â˜† |

---

## ğŸ“ Structure du projet

```
scoring-churn/
â”‚
â”œâ”€â”€ main.py                    # â–¶ Point d'entrÃ©e â€” lance le pipeline complet
â”œâ”€â”€ requirements.txt           # DÃ©pendances Python
â”œâ”€â”€ README.md
â”œâ”€â”€ .gitignore
â”‚
â”œâ”€â”€ src/                       # Code source
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ loader.py          # Chargement & renommage des colonnes
â”‚   â”‚   â””â”€â”€ cleaner.py         # Valeurs manquantes + outliers IQR
â”‚   â”‚
â”‚   â”œâ”€â”€ features/
â”‚   â”‚   â”œâ”€â”€ engineering.py     # DiscrÃ©tisation, regroupement, WOE/IV
â”‚   â”‚   â””â”€â”€ stats_tests.py     # Mann-Whitney, ChiÂ², V de Cramer
â”‚   â”‚
â”‚   â”œâ”€â”€ models/
â”‚   â”‚   â””â”€â”€ train.py           # Pipelines RÃ©gression Logistique + Random Forest
â”‚   â”‚
â”‚   â””â”€â”€ visualization/
â”‚       â””â”€â”€ plots.py           # Toutes les fonctions de visualisation
â”‚
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                   # csv 
â”‚   â””â”€â”€ processed/             # DonnÃ©es transformÃ©es 
â”‚
â”œâ”€â”€ outputs/
â”‚   â”œâ”€â”€ figures/               # Graphiques gÃ©nÃ©rÃ©s (ROC, confusion, etc.)

```

---

## ğŸ› ï¸ Outils nÃ©cessaires pour lancer le projet

| Outil | Version utilisÃ©e |
|-------|-----------------|
| Python | 3.11.x |
| pip | 24.x |

VÃ©rifiez vos versions :

```bash
python --version
pip --version
```

---

## ğŸš€ Installation et lancement

### 1. Cloner le projet

```bash
git clone https://github.com/marouane-nouara/scoring-churn.git
cd scoring-churn
```

### 2. CrÃ©er un environnement virtuel

```bash
python -m venv .venv
source .venv/bin/activate
```

### 3. Installer les dÃ©pendances

```bash
pip install -r requirements.txt
```

### 4. Placer le dataset

```bash
# Copier votre fichier BDD_PROJETS.csv dans data/raw/
cp /chemin/vers/BDD_PROJETS.csv data/raw/BDD_PROJETS.csv
```

### 5. Lancer le pipeline complet

```bash
python main.py --data data/raw/BDD_PROJETS.csv
```

Les rÃ©sultats sont automatiquement sauvegardÃ©s dans :
- `outputs/figures/` â€” tous les graphiques (ROC, confusion, importances...)
- `outputs/models/` â€” modÃ¨les entraÃ®nÃ©s (`logistic_regression.pkl`, `random_forest.pkl`)

---

## ğŸ§ª Lancer les tests

```bash
pytest tests/ -v
```

---

## ğŸ“¦ DÃ©sactiver l'environnement virtuel

```bash
deactivate
```


## ğŸ”¬ MÃ©thodologie dÃ©taillÃ©e

### Traitement des valeurs manquantes
- **4 variables** avec 49 valeurs manquantes â†’ imputation par mÃ©diane/moyenne
- **8 variables** avec 7 valeurs manquantes â†’ imputation par mode (catÃ©gorielles)

### Traitement des outliers (IQR Clipping)
```
IQR = Q3 âˆ’ Q1
Borne infÃ©rieure = Q1 âˆ’ 1.5 Ã— IQR
Borne supÃ©rieure = Q3 + 1.5 Ã— IQR
```
*Exemple : Limite de crÃ©dit rÃ©duite de 654M â†’ max 23 828 â‚¬*

### SÃ©lection des variables
Variables exclues aprÃ¨s tests statistiques et analyse de corrÃ©lation :
- `Moyenne_disponible_pour_achats` (corrÃ©lÃ©e Ã  0.99 avec `Limite_de_crÃ©dit`)
- `Montant_total_transactions` (corrÃ©lÃ©e Ã  0.86 avec `Nombre_total_transactions`)
- `AnciennetÃ©` (corrÃ©lÃ©e Ã  0.78 avec `Age`)

### Gestion du dÃ©sÃ©quilibre des classes
- Seulement **16% de clients rÃ©siliÃ©s** dans le dataset
- Technique : **SMOTE** (Synthetic Minority Oversampling Technique) + `class_weight='balanced'`
